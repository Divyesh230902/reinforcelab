export const highlightCards = [
  {
    title: "Tailored Learning Environments",
    description:
      "Design domain-specific simulators where agents can explore safely before they ever touch production."
  },
  {
    title: "Actively Learning AI Agents",
    description:
      "Deploy agents that ingest real feedback loops, adapting policies as objectives and constraints evolve."
  },
  {
    title: "Simulation-First Experimentation",
    description:
      "Model permutations, stress test strategies, and surface emergent behaviors across complex scenarios."
  },
  {
    title: "Beyond Conventional AI Pipelines",
    description:
      "Evolve from static LLM workflows to adaptive decision systems that deliver measurable business outcomes."
  }
];

export const services = [
  {
    name: "Adaptive Intelligence Consulting",
    summary:
      "Blueprint reinforcement learning programs that align KPIs with reward design and strategic impact.",
    details: [
      "Translate business goals into reinforcement learning frameworks and experimentation roadmaps.",
      "Map KPIs to reward signals, identify adaptive automation opportunities, and define ROI metrics.",
      "Bridge data science with operations to deliver continuous learning transformations."
    ]
  },
  {
    name: "Simulation Environment Design",
    summary:
      "Craft synthetic environments that de-risk policy learning before high-stakes deployment.",
    details: [
      "Build virtual testbeds across pricing, logistics, and marketing use cases with real-world data.",
      "Model feedback loops, multi-agent dynamics, and event rarity to accelerate policy robustness.",
      "Provision scalable cloud or edge environments with observability baked in."
    ]
  },
  {
    name: "Policy Learning and Optimization",
    summary:
      "Engineer adaptive policies that thrive amid market volatility and operational complexity.",
    details: [
      "Leverage bandits, Deep Q-Learning, and continual learning pipelines across historical and live data.",
      "Shape rewards to mirror business constraints and maintain balanced exploration-exploitation.",
      "Benchmark policies across simulation and production footprints with safety gates."
    ]
  },
  {
    name: "RL Integration and Deployment",
    summary:
      "Embed adaptive decision layers seamlessly inside enterprise stacks and workflows.",
    details: [
      "Expose policy APIs into CRM, ERP, and recommender systems with secure guardrails.",
      "Support low-latency inference, CI/CD retraining, and compliance-grade observability.",
      "Harmonize with existing data pipelines and monitoring ecosystems."
    ]
  },
  {
    name: "Managed RL-as-a-Service",
    summary:
      "Operate reinforcement learning systems end-to-end with outcome-based SLAs.",
    details: [
      "Deliver plug-and-play infrastructure that supports multi-agent workloads at scale.",
      "Automate evaluation, drift correction, versioning, and policy rollouts.",
      "Run feedback-driven retraining cycles and performance operations under one managed service."
    ]
  },
  {
    name: "Analytics and Governance",
    summary:
      "Provide the transparency and accountability adaptive systems demand.",
    details: [
      "Produce interpretability dossiers, ROI audits, and fairness diagnostics.",
      "Maintain executive-ready dashboards covering compliance, ethics, and real-world impact.",
      "Instrument continuous analytics to monitor outcomes and reinforce trust."
    ]
  }
];

export const solutions = [
  {
    name: "Adaptive Recommendation Engine",
    summary:
      "Personalize content sequencing with ensemble bandits and hierarchical clustering.",
    details: [
      "Learns from user behavior and context to balance discovery with conversion.",
      "Adapts to price sensitivity and trend signals across digital touchpoints.",
      "Plugs into e-commerce and media platforms to boost retention and LTV."
    ]
  },
  {
    name: "Dynamic Pricing & Demand Optimization",
    summary:
      "Optimize margin and conversion with RL-driven pricing that reacts in real time.",
    details: [
      "Models elasticity, competitor response, and seasonality with multi-objective rewards.",
      "Executes adaptive price testing and contextual experiments continuously.",
      "Serves retail, SaaS, and travel scenarios with rigorous guardrails."
    ]
  },
  {
    name: "Operational Workflow Optimizer",
    summary:
      "Continuously streamline operations with agents that learn from every task.",
    details: [
      "Automates scheduling, routing, and prioritization with reinforcement signals.",
      "Predicts downtime, reallocates resources, and scales with demand fluctuations.",
      "Integrates with ERP, logistics, and workflow platforms to cut cost and latency."
    ]
  },
  {
    name: "Personalized Engagement Engine",
    summary:
      "Evolve marketing pipelines with campaigns that self-tune for lifetime value.",
    details: [
      "Optimizes message cadence, channel selection, and tone in real time.",
      "Sequences experiences across the customer journey using reward shaping.",
      "Connects to CRM and marketing automation for closed-loop learning."
    ]
  },
  {
    name: "Resource Allocation & Simulation Suite",
    summary:
      "Model complex environments to orchestrate assets, fleets, and supply chains.",
    details: [
      "Simulates logistics, traffic, energy, or IoT scenarios with sensor feedback.",
      "Runs sensitivity analyses and stress tests for multi-agent coordination.",
      "Delivers APIs and dashboards for operations teams to operationalize insight."
    ]
  },
  {
    name: "Decision Intelligence Dashboard",
    summary:
      "Deliver executive transparency into every adaptive decision cycle.",
    details: [
      "Visualizes policy evolution, reward curves, and comparative performance.",
      "Supports explainability, compliance reporting, and BI integrations.",
      "Automates governance workflows with auditable intelligence."
    ]
  }
];

export const researchPillars = [
  {
    name: "RLX Leaderboards",
    description:
      "Benchmark agents on exploration, generalization, and safety metrics with transparent scorecards."
  },
  {
    name: "Self-Reflective Learning (SRL)",
    description:
      "Teach agents to audit their own trajectories, revise strategies, and document reasoning trails."
  },
  {
    name: "Meta-Ethical Reward Shaping",
    description:
      "Align policies with nuanced cultural and human values via value-sensitive reward engineering."
  },
  {
    name: "Safe-RL Protocols",
    description:
      "Engineer verifiably robust policies for high-risk domains with formal safeguards."
  }
];

export const metrics = [
  {
    label: "AgentOps Observability",
    stat: "45+",
    description:
      "prebuilt monitors track policy drift, governance, and in-flight performance."
  },
  {
    label: "Enterprise-Grade Security",
    stat: "SOC 2",
    description:
      "aligned controls with data residency, access auditing, and zero-trust deployment."
  },
  {
    label: "ROI Acceleration",
    stat: "8-12 mo",
    description:
      "average time to measurable uplift across pricing, operations, and engagement programs."
  }
];

export const navLinks = [
  { label: "Services", href: "#services" },
  { label: "Solutions", href: "#solutions" },
  { label: "Research", href: "#research" },
  { label: "About", href: "#about" },
  { label: "Contact", href: "#contact" }
];

